{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c4a7104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from pathlib import PurePath\n",
    "import pandas as pd\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers, models, datasets, callbacks, utils, metrics, optimizers\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from tensorflow.keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3499d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH =\"Train_Submission/Sound_Drum\"\n",
    "SAMPLE_RATE=22050\n",
    "DURATION=10\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "JSON_PATH = \"data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f4f1988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_audio_files_by_channels(folder_path):\n",
    "    # List all files in the folder\n",
    "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "    # Separate mono and multichannel files\n",
    "    mono_files = []\n",
    "    multichannel_files = []\n",
    "\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Check the number of channels using librosa\n",
    "        signal,_ = librosa.load(file_path, mono=False)\n",
    "#         print(signal.shape)\n",
    "\n",
    "        if len(signal.shape) > 1:\n",
    "            multichannel_files.append(file_name)\n",
    "            \n",
    "        else:\n",
    "            mono_files.append(file_name)\n",
    "           \n",
    "\n",
    "    return mono_files, multichannel_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e34c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "monofiles, multichannel_files = sort_audio_files_by_channels(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5c09f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "563"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(monofiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a4c4a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multichannel_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66341a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "from scipy.io import wavfile\n",
    "def convert_to_fixed_size(dataset_path,  target_duration, multichannel_files):\n",
    "    for i, (dirpath, dirname, filenames) in enumerate(os.walk(dataset_path)):\n",
    "        \n",
    "        #ensure that we're not at the root level\n",
    "        if dirpath is not dataset_path:\n",
    "            #Get the Semantic Label\n",
    "            dirpath_components = dirpath.split(\"\\\\\")\n",
    "            sematic_label = dirpath_components[-1]\n",
    "                        \n",
    "            for f in multichannel_files:\n",
    "                input_file = os.path.join(dirpath, f)\n",
    "                output_folder = os.path.dirname(dataset_path) +'/fixed'\n",
    "                \n",
    "                if not os.path.exists(output_folder):\n",
    "                    os.makedirs(output_folder)\n",
    "                \n",
    "                output_file = f\n",
    "                # Load the audio file\n",
    "                y, sr = librosa.load(input_file, mono=False, sr=None)\n",
    "#                 print(len(y[0]))\n",
    "                \n",
    "                target_samples = int(sr*target_duration)\n",
    "                \n",
    "                if len(y[0]) > target_samples:\n",
    "                    y_fixed_length = y[:, :target_samples]\n",
    "                else:\n",
    "                    pad_length = target_samples - len(y[0])\n",
    "                    y_fixed_length = np.pad(y, ((0,0),(0, pad_length)), 'constant')\n",
    "#                 print(\"{} : {}\\n\".format(type(y_fixed_length), y_fixed_length.shape))\n",
    "                y_fixed_length = y_fixed_length.T\n",
    "                    \n",
    "                sf.write(output_file, y_fixed_length, sr )\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44a484e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_fixed_size('Train_Submission', 10, multichannel_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3fa58d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['04-47367.wav',\n",
       " '046578_tribal-drum-rhythms-03wav-68096.wav',\n",
       " '054399_8039s-old-school-rap-drum-loop-80433.wav',\n",
       " '056514_drum-40118.wav',\n",
       " '059960_sonido2-sincopa-alta-7mp3-47316.wav',\n",
       " '065339_metal-bass-drum-90850.wav',\n",
       " '066166_qui-c39est-qu39est-tombe-loop-t85wav-39366.wav',\n",
       " '068320_hang-drum-2wav-80568.wav',\n",
       " '102-bpm-boom-groove-82498.wav',\n",
       " '109-bpm-70s-style-drum-loop-76138.wav',\n",
       " '10_drumloop_minimal-32725.wav',\n",
       " '120bpm_kick-build-up-98848.wav',\n",
       " '140-bpm-amen-break-original-processed-6945 (1).wav',\n",
       " '140-bpm-amen-break-original-processed-6945.wav',\n",
       " '170-beat-box-hpf-loop-103412.wav',\n",
       " '174-txls4-106297.wav',\n",
       " '2018-11-15-22563.wav',\n",
       " '808-d3-38858.wav',\n",
       " '80s-drums-fl-studio-70248.wav',\n",
       " '8bit-sample-69080.wav',\n",
       " 'action-drums-78-low-67673.wav',\n",
       " 'african-98600.wav',\n",
       " 'agressive-straight-drums-105-bpm-99895.wav',\n",
       " 'alien-beeper-103420.wav',\n",
       " 'asian-gong-102397.wav',\n",
       " 'atari-st-beat-09-106443.wav',\n",
       " 'ba-dum-bum-all-74740.wav',\n",
       " 'bar-bq-chicken-drumpsticks-129354.wav',\n",
       " 'bass-loops-003-with-drums-long-loop-120-bpm-24371.wav',\n",
       " 'bass-loops-006-with-drums-long-loop-120-bpm-6111.wav',\n",
       " 'battle-preparations-6726.wav',\n",
       " 'beat-of-time-128705.wav',\n",
       " 'beatboxlong-72000.wav',\n",
       " 'big-cinematic-impact-94799.wav',\n",
       " 'boje-3-87816.wav',\n",
       " 'bongo-and-drum-instrumental-music-21295.wav',\n",
       " 'boss-rhythm-1-37451.wav',\n",
       " 'boss-sp-303-drum-rhythm-200-bpm-8437.wav',\n",
       " 'break-delay-88443.wav',\n",
       " 'brushes-loop-77bpm-by-canis-et-circensis-91191.wav',\n",
       " 'catchy-electronic-drum-solo-100-bpm-by-prettysleepy-108532.wav',\n",
       " 'chasing-drums-100-bpm-41050.wav',\n",
       " 'chill-drum-loop-6887.wav',\n",
       " 'cinematic-handpan-100bpm-25170.wav',\n",
       " 'cool-drum-beat-loop-109650.wav',\n",
       " 'cool-hiphop-beat-43890.wav',\n",
       " 'crazy-rhythm-loop-120-bpm-0015-68064.wav',\n",
       " 'crazy-rhythm-loop-120-bpm-002-68061.wav',\n",
       " 'crazy-rhythm-loop-120-bpm-006-68062.wav',\n",
       " 'dance-vol-1-7082.wav',\n",
       " 'darkbeat76bpm-87710.wav',\n",
       " 'deep-trap-beat-66414.wav',\n",
       " 'digital-pulse-140-2-122269.wav',\n",
       " 'dirty-rising-tube-32714.wav',\n",
       " 'distorted-kick-1-98539.wav',\n",
       " 'dnb-bass2-106724.wav',\n",
       " 'dnb-bassline-170-bpm-85155.wav',\n",
       " 'dr-tribal-percussion-triplet-loop-high-passed-106bpm-25935.wav',\n",
       " 'dramatic-reveal-21469.wav',\n",
       " 'drum-01-69203.wav',\n",
       " 'drum-beat-02-36276.wav',\n",
       " 'drum-beat-bpm-120-113150.wav',\n",
       " 'drum-beat-loop-3-96537.wav',\n",
       " 'drum-groove-71987.wav',\n",
       " 'drum-intro-1-113201.wav',\n",
       " 'drum-loop-140bpm-73728 (1).wav',\n",
       " 'drum-loop-140bpm-73728.wav',\n",
       " 'drum-loop-43751.wav',\n",
       " 'drum-roll-please-6386.wav',\n",
       " 'drum-solo-150-bpm-by-prettysleepy-art-12975.wav',\n",
       " 'drums-buildup-3-84503.wav',\n",
       " 'drums-dembow-rd-loop-26-13497.wav',\n",
       " 'drums-rap-type-1-oldschool-loop-22-13062.wav',\n",
       " 'DRUM_SOUND (1).wav',\n",
       " 'DRUM_SOUND (2).wav',\n",
       " 'dr_ni-timpani_drums-klangraum-wort-6790.wav',\n",
       " 'dr_ni_india_01-klang-raum-wort-29461.wav',\n",
       " 'dumdum-105423.wav',\n",
       " 'dystopian-drum-12331.wav',\n",
       " 'electro-drum-beat-78-bpm-99903.wav',\n",
       " 'electronic-drum-loop-by-prettysleepy-art-12918.wav',\n",
       " 'epic-extreme-hit-109132.wav',\n",
       " 'epic-logo-6906.wav',\n",
       " 'epic_battle_music_1-6275.wav',\n",
       " 'fillin-fill-timbal-edm-reggae-loop-18-12766.wav',\n",
       " 'flying-over-the-hill-handpan-atmos-19989.wav',\n",
       " 'freedom-in-sight-130bpm-32759.wav',\n",
       " 'funk-bitxl-op-i1-34289.wav',\n",
       " 'funky-drummer-drum-kit-94738.wav',\n",
       " 'funny-light-optimistic-111775.wav',\n",
       " 'gabber-breakbeat-145bpm-wav-103637.wav',\n",
       " 'giant-kit-77973.wav',\n",
       " 'glitch-beat-001-128-bpm-99953.wav',\n",
       " 'grave-metronomico-99387.wav',\n",
       " 'grinder-drum-loop-6697.wav',\n",
       " 'grunge-bounce-drum-loop-40464.wav',\n",
       " 'happy-day-in-beach-hand-panwav-14755.wav',\n",
       " 'happy-loop-6978.wav',\n",
       " 'hard-edm-drum-loop-140-bpm-37696.wav',\n",
       " 'hard-rock-logo-108960.wav',\n",
       " 'heartbeat-fast-slowdown-31706.wav',\n",
       " 'heartbeat-foley-34902.wav',\n",
       " 'heavy-thump-drum-line-89744.wav',\n",
       " 'heavy-tribal-beat-76580.wav',\n",
       " 'hectic-808-drum-loop-32989.wav',\n",
       " 'hi-hat-rhythm-89806.wav',\n",
       " 'hihat-loop-bpm140-107127.wav',\n",
       " 'hip-hop-drum-loop-23-75663.wav',\n",
       " 'hip-hop-drum-loop-24-75662.wav',\n",
       " 'hipsnare-85814.wav',\n",
       " 'hitting-ride-bell-with-a-finger-98356.wav',\n",
       " 'hybrid-drum-groove-41326.wav',\n",
       " 'industrial-drums-2-115bpm-80848.wav',\n",
       " 'intro_ezezez-74457.wav',\n",
       " 'james-brown-type-drum-loop-120bpm-129551.wav',\n",
       " 'jungleloop-87697.wav',\n",
       " 'kastimes-drum-sample-7-35739.wav',\n",
       " 'kc-mus152-jungle-beat-63962.wav',\n",
       " 'kick-drum-f-14574.wav',\n",
       " 'kokaji-beatbox-32048.wav',\n",
       " 'lckk_118_drum_01_full-43553.wav',\n",
       " 'lets-dance-126506.wav',\n",
       " 'loop-12-107632.wav',\n",
       " 'loop-16247.wav',\n",
       " 'loopx2-90402.wav',\n",
       " 'marching-drums-drum-solo2-fx-99061.wav',\n",
       " 'mattc-hectik-beat-box-01qw-99855.wav',\n",
       " 'menu-music-28480.wav',\n",
       " 'metronomico-45663.wav',\n",
       " 'minimal-beat-81778.wav',\n",
       " 'muvibeat8_130bpm-14338.wav',\n",
       " 'muvibeat9_130bpm-14339.wav',\n",
       " 'new-9-42628.wav',\n",
       " 'odddrumloop-91606.wav',\n",
       " 'on-rd-bruce-drums-1-89708.wav',\n",
       " 'orch-006-cymbal-rollwav-14781.wav',\n",
       " 'orchestral-drums-28182.wav']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multichannel_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4990810",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Train_Meta_File.txt\", 'w') as file:\n",
    "    file.write(','.join(multichannel_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08ce43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_audio(file_path, target_sr=22050, duration=10, n_fft=2048, hop_length=512, n_mfcc=100):\n",
    "    #Load audio file\n",
    "    y,sr = librosa.load(file_path, sr=target_sr, duration=duration, mono=False)\n",
    "    \n",
    "    #Extract features (e.g. spectrogram)\n",
    "    features = librosa.feature.mfcc(y=y, sr=target_sr, n_fft=n_fft, hop_length=hop_length, n_mels=128)\n",
    "    features = librosa.power_to_db(features, ref=np.max)\n",
    "    \n",
    "    \n",
    "    #if you have multiple channels, stack them along the third axis\n",
    "    if len(y.shape) > 1:\n",
    "        features = np.stack([features]*y.shape[0], axis=-1)\n",
    "        \n",
    "    else: \n",
    "        print(\"Skipping File...\\n\")\n",
    "        return\n",
    "        \n",
    "    reduced_features = np.mean(features, axis=-1)\n",
    "    #Normalize the features\n",
    "    normalized_features = (reduced_features - np.min(reduced_features)) / (np.max(reduced_features) - np.min(reduced_features))\n",
    "    normalized_features = normalized_features.T\n",
    "    return normalized_features\n",
    "\n",
    "\n",
    "def preprocess_and_save_to_npz(input_folder, sr=22050, duration=10, hop_length=512):\n",
    "    #Assuming each aduio file in the folder is a multichannel audio file\n",
    "    audio_files = [f for f in os.listdir(input_folder) if f.endswith('.wav')]\n",
    "    \n",
    "    num_of_samples_per_file = int(sr*duration)\n",
    "    expected_num_vectors_per_file = math.ceil(num_of_samples_per_file/hop_length)\n",
    "    \n",
    "    data = {}\n",
    "    mfcc_dict = {}\n",
    "    for file_name in audio_files:\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        audio_data = load_and_preprocess_audio(file_path)\n",
    "        mfcc_dict[file_name] = audio_data\n",
    "#         print(audio_data.shape[2], expected_num_vectors_per_file, type(audio_data))\n",
    "#         semantics = input_folder.split('/')\n",
    "#         print(semantics)\n",
    "#         key = semantics[-1]\n",
    "#         if audio_data.shape[2] == expected_num_vectors_per_file:\n",
    "#             if key in data:\n",
    "#                 data[key].append(audio_data.tolist())\n",
    "#             else:\n",
    "#                 data[key]=audio_data.tolist()\n",
    "        \n",
    "#     with open(output_json, 'w') as json_file:\n",
    "#         json.dump(data, json_file, indent=4)\n",
    "    np.savez(\"mfcc_data_drums.npz\", **mfcc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "981d6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_and_save_to_npz(\"Multichannel_Fixed_Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33b1f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = np.load(\"mfcc_data_drums.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2299561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = loaded_data['04-47367.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59c3c1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431, 20, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba68030c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        ],\n",
       "        [0.85915077, 0.8529997 ],\n",
       "        [0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        ],\n",
       "        [0.7974676 , 0.7970575 ],\n",
       "        [0.7091631 , 0.6313097 ]],\n",
       "\n",
       "       [[0.        , 0.        ],\n",
       "        [0.95580405, 0.9553362 ],\n",
       "        [0.9215112 , 0.9210318 ],\n",
       "        ...,\n",
       "        [0.73916245, 0.74817485],\n",
       "        [0.        , 0.        ],\n",
       "        [0.83489865, 0.8291292 ]],\n",
       "\n",
       "       [[0.9309942 , 0.93171597],\n",
       "        [0.95782626, 0.9569068 ],\n",
       "        [0.9176909 , 0.9177766 ],\n",
       "        ...,\n",
       "        [0.715199  , 0.61785376],\n",
       "        [0.        , 0.        ],\n",
       "        [0.75366133, 0.7416283 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.        ],\n",
       "        [0.        , 0.        ],\n",
       "        [0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        ],\n",
       "        [0.        , 0.        ],\n",
       "        [0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        ],\n",
       "        [0.        , 0.        ],\n",
       "        [0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        ],\n",
       "        [0.        , 0.        ],\n",
       "        [0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        ],\n",
       "        [0.        , 0.        ],\n",
       "        [0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        ],\n",
       "        [0.        , 0.        ],\n",
       "        [0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53791fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['04-47367.wav', '046578_tribal-drum-rhythms-03wav-68096.wav', '054399_8039s-old-school-rap-drum-loop-80433.wav', '056514_drum-40118.wav', '059960_sonido2-sincopa-alta-7mp3-47316.wav', '065339_metal-bass-drum-90850.wav', '066166_qui-c39est-qu39est-tombe-loop-t85wav-39366.wav', '068320_hang-drum-2wav-80568.wav', '102-bpm-boom-groove-82498.wav', '109-bpm-70s-style-drum-loop-76138.wav', '10_drumloop_minimal-32725.wav', '120bpm_kick-build-up-98848.wav', '140-bpm-amen-break-original-processed-6945 (1).wav', '140-bpm-amen-break-original-processed-6945.wav', '170-beat-box-hpf-loop-103412.wav', '174-txls4-106297.wav', '2018-11-15-22563.wav', '808-d3-38858.wav', '80s-drums-fl-studio-70248.wav', '8bit-sample-69080.wav', 'action-drums-78-low-67673.wav', 'african-98600.wav', 'agressive-straight-drums-105-bpm-99895.wav', 'alien-beeper-103420.wav', 'asian-gong-102397.wav', 'atari-st-beat-09-106443.wav', 'ba-dum-bum-all-74740.wav', 'bar-bq-chicken-drumpsticks-129354.wav', 'bass-loops-003-with-drums-long-loop-120-bpm-24371.wav', 'bass-loops-006-with-drums-long-loop-120-bpm-6111.wav', 'battle-preparations-6726.wav', 'beat-of-time-128705.wav', 'beatboxlong-72000.wav', 'big-cinematic-impact-94799.wav', 'boje-3-87816.wav', 'bongo-and-drum-instrumental-music-21295.wav', 'boss-rhythm-1-37451.wav', 'boss-sp-303-drum-rhythm-200-bpm-8437.wav', 'break-delay-88443.wav', 'brushes-loop-77bpm-by-canis-et-circensis-91191.wav', 'catchy-electronic-drum-solo-100-bpm-by-prettysleepy-108532.wav', 'chasing-drums-100-bpm-41050.wav', 'chill-drum-loop-6887.wav', 'cinematic-handpan-100bpm-25170.wav', 'cool-drum-beat-loop-109650.wav', 'cool-hiphop-beat-43890.wav', 'crazy-rhythm-loop-120-bpm-0015-68064.wav', 'crazy-rhythm-loop-120-bpm-002-68061.wav', 'crazy-rhythm-loop-120-bpm-006-68062.wav', 'dance-vol-1-7082.wav', 'darkbeat76bpm-87710.wav', 'deep-trap-beat-66414.wav', 'digital-pulse-140-2-122269.wav', 'dirty-rising-tube-32714.wav', 'distorted-kick-1-98539.wav', 'dnb-bass2-106724.wav', 'dnb-bassline-170-bpm-85155.wav', 'dr-tribal-percussion-triplet-loop-high-passed-106bpm-25935.wav', 'dramatic-reveal-21469.wav', 'drum-01-69203.wav', 'drum-beat-02-36276.wav', 'drum-beat-bpm-120-113150.wav', 'drum-beat-loop-3-96537.wav', 'drum-groove-71987.wav', 'drum-intro-1-113201.wav', 'drum-loop-140bpm-73728 (1).wav', 'drum-loop-140bpm-73728.wav', 'drum-loop-43751.wav', 'drum-roll-please-6386.wav', 'drum-solo-150-bpm-by-prettysleepy-art-12975.wav', 'drums-buildup-3-84503.wav', 'drums-dembow-rd-loop-26-13497.wav', 'drums-rap-type-1-oldschool-loop-22-13062.wav', 'DRUM_SOUND (1).wav', 'DRUM_SOUND (2).wav', 'dr_ni-timpani_drums-klangraum-wort-6790.wav', 'dr_ni_india_01-klang-raum-wort-29461.wav', 'dumdum-105423.wav', 'dystopian-drum-12331.wav', 'electro-drum-beat-78-bpm-99903.wav', 'electronic-drum-loop-by-prettysleepy-art-12918.wav', 'epic-extreme-hit-109132.wav', 'epic-logo-6906.wav', 'epic_battle_music_1-6275.wav', 'fillin-fill-timbal-edm-reggae-loop-18-12766.wav', 'flying-over-the-hill-handpan-atmos-19989.wav', 'freedom-in-sight-130bpm-32759.wav', 'funk-bitxl-op-i1-34289.wav', 'funky-drummer-drum-kit-94738.wav', 'funny-light-optimistic-111775.wav', 'gabber-breakbeat-145bpm-wav-103637.wav', 'giant-kit-77973.wav', 'glitch-beat-001-128-bpm-99953.wav', 'grave-metronomico-99387.wav', 'grinder-drum-loop-6697.wav', 'grunge-bounce-drum-loop-40464.wav', 'happy-day-in-beach-hand-panwav-14755.wav', 'happy-loop-6978.wav', 'hard-edm-drum-loop-140-bpm-37696.wav', 'hard-rock-logo-108960.wav', 'heartbeat-fast-slowdown-31706.wav', 'heartbeat-foley-34902.wav', 'heavy-thump-drum-line-89744.wav', 'heavy-tribal-beat-76580.wav', 'hectic-808-drum-loop-32989.wav', 'hi-hat-rhythm-89806.wav', 'hihat-loop-bpm140-107127.wav', 'hip-hop-drum-loop-23-75663.wav', 'hip-hop-drum-loop-24-75662.wav', 'hipsnare-85814.wav', 'hitting-ride-bell-with-a-finger-98356.wav', 'hybrid-drum-groove-41326.wav', 'industrial-drums-2-115bpm-80848.wav', 'intro_ezezez-74457.wav', 'james-brown-type-drum-loop-120bpm-129551.wav', 'jungleloop-87697.wav', 'kastimes-drum-sample-7-35739.wav', 'kc-mus152-jungle-beat-63962.wav', 'kick-drum-f-14574.wav', 'kokaji-beatbox-32048.wav', 'lckk_118_drum_01_full-43553.wav', 'lets-dance-126506.wav', 'loop-12-107632.wav', 'loop-16247.wav', 'loopx2-90402.wav', 'marching-drums-drum-solo2-fx-99061.wav', 'mattc-hectik-beat-box-01qw-99855.wav', 'menu-music-28480.wav', 'metronomico-45663.wav', 'minimal-beat-81778.wav', 'muvibeat8_130bpm-14338.wav', 'muvibeat9_130bpm-14339.wav', 'new-9-42628.wav', 'odddrumloop-91606.wav', 'on-rd-bruce-drums-1-89708.wav', 'orch-006-cymbal-rollwav-14781.wav', 'orchestral-drums-28182.wav']\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "with open('Train_Meta_File.txt', 'r') as file:\n",
    "  data = file.read().replace('\\n', '')\n",
    "  files_list = data.split(',')\n",
    "\n",
    "print(files_list)\n",
    "print(len(files_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "958b55fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 431, 20, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.load('mfcc_data_drums.npz')\n",
    "X_train = []\n",
    "for file in files_list:\n",
    "  X_train.append(train_data[file])\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17536132",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trimmed = X_train[:, :420, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ae2c11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 420, 20, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trimmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba15cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 13\n",
    "real_series = (tf.data.Dataset.from_tensor_slices(X_train)\n",
    "                .batch(batch_size, drop_remainder=True))\n",
    "real_series_iter = iter(real_series.repeat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f891e473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.data.ops.iterator_ops.OwnedIterator at 0x1aac299deb0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_series_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0500d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_data():\n",
    "    while True:\n",
    "        yield np.random.normal(low=0, high=1, size=(431,20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77218901",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_series = iter(tf.data.Dataset\n",
    "                     .from_generator(make_random_data, output_types=tf.float32)\n",
    "                     .batch(batch_size)\n",
    "                     .repeat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a82b5391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_RepeatDataset element_spec=TensorSpec(shape=<unknown>, dtype=tf.float32, name=None)>\n"
     ]
    }
   ],
   "source": [
    "print(random_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9979002",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DIM = 420\n",
    "Y_DIM = 20\n",
    "Z_DIM = 2\n",
    "EMBEDDING_DIM = 420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71e51e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE BEFORE FLATTENING THE EMBEDDER NETWORK (105, 5, 128)\n",
      "EMBEDDER NETWORK LOOKS LIKE : \n",
      "\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 420, 20, 2)]      0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 210, 10, 64)       1216      \n",
      "                                                                 \n",
      " leaky_re_lu_84 (LeakyReLU)  (None, 210, 10, 64)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 105, 5, 128)       73856     \n",
      "                                                                 \n",
      " leaky_re_lu_85 (LeakyReLU)  (None, 105, 5, 128)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 105, 5, 128)       0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 105, 5, 128)       147584    \n",
      "                                                                 \n",
      " leaky_re_lu_86 (LeakyReLU)  (None, 105, 5, 128)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 105, 5, 128)       0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 105, 5, 128)       147584    \n",
      "                                                                 \n",
      " leaky_re_lu_87 (LeakyReLU)  (None, 105, 5, 128)       0         \n",
      "                                                                 \n",
      " embedder_ouput (Dense)      (None, 105, 5, 420)       54180     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 424420 (1.62 MB)\n",
      "Trainable params: 424420 (1.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Embedder\n",
    "embedder_input = layers.Input(shape=(X_DIM, Y_DIM, Z_DIM))   ## Image Size height, width, channels\n",
    "# label_input = layers.Input(shape = (87, 50, 15))\n",
    "\n",
    "# e = layers.Concatenate(axis=-1)([embedder_input, label_input])\n",
    "e = layers.Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(embedder_input)\n",
    "e = layers.LeakyReLU(0.2)(e)\n",
    "e = layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(e)\n",
    "e = layers.LeakyReLU()(e)\n",
    "e = layers.Dropout(0.3)(e)\n",
    "e = layers.Conv2D(128, kernel_size=3, strides=1, padding=\"same\")(e)\n",
    "e = layers.LeakyReLU(0.2)(e)\n",
    "e = layers.Dropout(0.3)(e)\n",
    "e = layers.Conv2D(128, kernel_size=3, strides=1, padding=\"same\")(e)\n",
    "e = layers.LeakyReLU(0.2)(e)\n",
    "shape_before_flattening = K.int_shape(e)[1:]\n",
    "print(\"SHAPE BEFORE FLATTENING THE EMBEDDER NETWORK {}\".format(shape_before_flattening))\n",
    "#e = layers.Flatten()(e)\n",
    "embedder_output = layers.Dense(EMBEDDING_DIM, name = \"embedder_ouput\")(e)\n",
    "embedder = tf.keras.Model(embedder_input, embedder_output)\n",
    "\n",
    "# embedder = models.Model([embedder_input, label_input], embedder_ouput)\n",
    "\n",
    "print(\"EMBEDDER NETWORK LOOKS LIKE : \\n\")\n",
    "embedder.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed926eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECOVERY NETWORK LOOKS LIKE: \n",
      "\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " RECOVERY_INPUT (InputLayer  [(None, 420)]             0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 67200)             28291200  \n",
      "                                                                 \n",
      " reshape_18 (Reshape)        (None, 105, 5, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_90 (Conv2  (None, 105, 5, 128)       147456    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_72 (Ba  (None, 105, 5, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_80 (LeakyReLU)  (None, 105, 5, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_91 (Conv2  (None, 105, 5, 128)       147456    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_73 (Ba  (None, 105, 5, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_81 (LeakyReLU)  (None, 105, 5, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_92 (Conv2  (None, 210, 10, 128)      147456    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_74 (Ba  (None, 210, 10, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_82 (LeakyReLU)  (None, 210, 10, 128)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_93 (Conv2  (None, 210, 10, 128)      147456    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_75 (Ba  (None, 210, 10, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_83 (LeakyReLU)  (None, 210, 10, 128)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_94 (Conv2  (None, 420, 20, 2)        2306      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28885378 (110.19 MB)\n",
      "Trainable params: 28884354 (110.19 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Recovery\n",
    "recovery_input = layers.Input(shape=(EMBEDDING_DIM,), name=\"RECOVERY_INPUT\")\n",
    "# label_input = layers.Input(shape=(15,))\n",
    "# r = layers.Concatenate(axis=-1)([recovery_input, label_input])\n",
    "r = layers.Dense(np.prod(shape_before_flattening))(recovery_input)\n",
    "r = layers.Reshape(shape_before_flattening)(r)\n",
    "r = layers.Conv2DTranspose(128, kernel_size=3, strides=1, padding=\"same\", use_bias=False)(r)\n",
    "r = layers.BatchNormalization(momentum=0.9)(r)\n",
    "r = layers.LeakyReLU(0.2)(r)\n",
    "r = layers.Conv2DTranspose(128, kernel_size=3, strides=1, padding=\"same\", use_bias=False)(r)\n",
    "r = layers.BatchNormalization(momentum=0.9)(r)\n",
    "r = layers.LeakyReLU(0.2)(r)\n",
    "r = layers.Conv2DTranspose(128, kernel_size=3, strides=2, padding=\"same\", use_bias=False)(r)\n",
    "r = layers.BatchNormalization(momentum=0.9)(r)\n",
    "r = layers.LeakyReLU(0.2)(r)\n",
    "r = layers.Conv2DTranspose(128, kernel_size=3, strides=1, padding=\"same\", use_bias=False)(r)\n",
    "r = layers.BatchNormalization(momentum=0.9)(r)\n",
    "r = layers.LeakyReLU(0.2)(r)\n",
    "recovery_output = layers.Conv2DTranspose(2, kernel_size=3, strides=2, padding=\"same\", activation=\"tanh\")(r)\n",
    "\n",
    "# recovery = models.Model([recovery_input, label_input], recovery_output)\n",
    "recovery = tf.keras.Model(recovery_input, recovery_output)\n",
    "print(\"RECOVERY NETWORK LOOKS LIKE: \\n\")\n",
    "recovery.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08f10d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda59930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
